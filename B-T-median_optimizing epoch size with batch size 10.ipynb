{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_T-cells_AS_EtOH-GDM_z-score.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DipankarJDutta/Biomarker-discovery-for-FASD-GDM-with-B-T-cells/blob/Optimizing-epoch-size/B-T-median_optimizing%20epoch%20size%20with%20batch%20size%2010.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86TLkXaLMzkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading essentials\n",
        "from numpy import loadtxt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72EdN6digaMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fixing random seed for reproducibility\n",
        "from numpy.random import seed\n",
        "seed(7)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL_LIVyLWKvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating model for KerasClassifier\n",
        "def create_model():\n",
        "    #create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(27, input_dim=29, activation='relu'))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    #compile model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf2BdOONOrca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load dataset\n",
        "dataset = loadtxt ('B-T-median.csv', delimiter = ',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYDe7ikEO-q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split dataset into input and output variables\n",
        "x = dataset [:, 0:29]\n",
        "y = dataset [:, 29]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q3xyQYHXY4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create model for gridsearch\n",
        "model = KerasClassifier (build_fn=create_model, batch_size = 10, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt5dX1ylX6Hs",
        "colab_type": "code",
        "outputId": "0a51a7d8-25c2-4da0-ec78-530970f4277d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#Define Grid Search parameters for optimal epoch size\n",
        "epochs = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250]\n",
        "param_grid = dict(epochs=epochs)\n",
        "#Jobs are run in parallel with n_jobs=-1; 10-fold cross-validation\n",
        "grid = GridSearchCV(estimator=model, param_grid = param_grid, n_jobs=-1, cv=10)\n",
        "grid_result = grid.fit(x, y)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeK4D0Tje30X",
        "colab_type": "code",
        "outputId": "ae22f422-dc1a-4fd1-cea4-600d64721bb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "#Summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.600000 using {'epochs': 240}\n",
            "0.526667 (0.227938) with: {'epochs': 10}\n",
            "0.560000 (0.267000) with: {'epochs': 20}\n",
            "0.543333 (0.243151) with: {'epochs': 30}\n",
            "0.560000 (0.233714) with: {'epochs': 40}\n",
            "0.500000 (0.205480) with: {'epochs': 50}\n",
            "0.566667 (0.213957) with: {'epochs': 60}\n",
            "0.520000 (0.230072) with: {'epochs': 70}\n",
            "0.396667 (0.205724) with: {'epochs': 80}\n",
            "0.570000 (0.253180) with: {'epochs': 90}\n",
            "0.523333 (0.229032) with: {'epochs': 100}\n",
            "0.540000 (0.220504) with: {'epochs': 110}\n",
            "0.536667 (0.250533) with: {'epochs': 120}\n",
            "0.443333 (0.233833) with: {'epochs': 130}\n",
            "0.533333 (0.165999) with: {'epochs': 140}\n",
            "0.493333 (0.205372) with: {'epochs': 150}\n",
            "0.450000 (0.152934) with: {'epochs': 160}\n",
            "0.480000 (0.230072) with: {'epochs': 170}\n",
            "0.426667 (0.133167) with: {'epochs': 180}\n",
            "0.450000 (0.219216) with: {'epochs': 190}\n",
            "0.390000 (0.181384) with: {'epochs': 200}\n",
            "0.413333 (0.124900) with: {'epochs': 210}\n",
            "0.563333 (0.202457) with: {'epochs': 220}\n",
            "0.553333 (0.238141) with: {'epochs': 230}\n",
            "0.600000 (0.170620) with: {'epochs': 240}\n",
            "0.390000 (0.165362) with: {'epochs': 250}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}