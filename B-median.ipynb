{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_T-cells_AS_EtOH-GDM_z-score.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DipankarJDutta/Biomarker-discovery-for-FASD-GDM-with-B-T-cells/blob/master/B-median.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86TLkXaLMzkK",
        "colab_type": "code",
        "outputId": "54f96e37-7ef1-4162-c636-eb1d2fc549fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Loading essentials\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72EdN6digaMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fixing random seed for reproducibility\n",
        "from numpy.random import seed\n",
        "seed(7)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf2BdOONOrca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load dataset\n",
        "dataset = loadtxt ('T-median.csv', delimiter = ',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYDe7ikEO-q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split dataset into input and output variables\n",
        "x = dataset [:, 0:13]\n",
        "y = dataset [:, 13]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIhgfFm9PDdS",
        "colab_type": "code",
        "outputId": "8c887814-fcc8-4320-9d71-93302d194213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#define the DL model\n",
        "model = Sequential ()\n",
        "model.add(Dense(12, input_dim=13, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cdclkz3PQ52",
        "colab_type": "code",
        "outputId": "d8377996-bd8a-45d6-8d35-b4be6a2a699b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "#compile the DL model \n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIRDdz_RPc76",
        "colab_type": "code",
        "outputId": "d7768d87-5a27-4c6f-becd-b30f53221353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Train the model with an epoch of 100, a batch size of 10, a validation split of 80-20)\n",
        "model.fit(x, y, validation_split = 0.2, epochs=200, batch_size=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 38 samples, validate on 10 samples\n",
            "Epoch 1/200\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.8570 - acc: 0.5263 - val_loss: 0.4874 - val_acc: 0.8000\n",
            "Epoch 2/200\n",
            "38/38 [==============================] - 0s 447us/step - loss: 0.8387 - acc: 0.5263 - val_loss: 0.4910 - val_acc: 0.8000\n",
            "Epoch 3/200\n",
            "38/38 [==============================] - 0s 338us/step - loss: 0.8152 - acc: 0.5263 - val_loss: 0.4951 - val_acc: 0.8000\n",
            "Epoch 4/200\n",
            "38/38 [==============================] - 0s 308us/step - loss: 0.8001 - acc: 0.5263 - val_loss: 0.5006 - val_acc: 0.8000\n",
            "Epoch 5/200\n",
            "38/38 [==============================] - 0s 286us/step - loss: 0.7812 - acc: 0.5263 - val_loss: 0.5069 - val_acc: 0.8000\n",
            "Epoch 6/200\n",
            "38/38 [==============================] - 0s 262us/step - loss: 0.7650 - acc: 0.5263 - val_loss: 0.5140 - val_acc: 0.8000\n",
            "Epoch 7/200\n",
            "38/38 [==============================] - 0s 293us/step - loss: 0.7460 - acc: 0.5263 - val_loss: 0.5213 - val_acc: 0.8000\n",
            "Epoch 8/200\n",
            "38/38 [==============================] - 0s 288us/step - loss: 0.7357 - acc: 0.5263 - val_loss: 0.5302 - val_acc: 0.8000\n",
            "Epoch 9/200\n",
            "38/38 [==============================] - 0s 273us/step - loss: 0.7226 - acc: 0.5263 - val_loss: 0.5396 - val_acc: 0.8000\n",
            "Epoch 10/200\n",
            "38/38 [==============================] - 0s 297us/step - loss: 0.7130 - acc: 0.5263 - val_loss: 0.5512 - val_acc: 0.8000\n",
            "Epoch 11/200\n",
            "38/38 [==============================] - 0s 315us/step - loss: 0.7047 - acc: 0.5526 - val_loss: 0.5645 - val_acc: 0.8000\n",
            "Epoch 12/200\n",
            "38/38 [==============================] - 0s 341us/step - loss: 0.6935 - acc: 0.5526 - val_loss: 0.5777 - val_acc: 0.8000\n",
            "Epoch 13/200\n",
            "38/38 [==============================] - 0s 284us/step - loss: 0.6900 - acc: 0.5789 - val_loss: 0.5939 - val_acc: 0.8000\n",
            "Epoch 14/200\n",
            "38/38 [==============================] - 0s 278us/step - loss: 0.6800 - acc: 0.5526 - val_loss: 0.6067 - val_acc: 0.8000\n",
            "Epoch 15/200\n",
            "38/38 [==============================] - 0s 318us/step - loss: 0.6745 - acc: 0.5789 - val_loss: 0.6175 - val_acc: 0.8000\n",
            "Epoch 16/200\n",
            "38/38 [==============================] - 0s 315us/step - loss: 0.6706 - acc: 0.6053 - val_loss: 0.6263 - val_acc: 0.8000\n",
            "Epoch 17/200\n",
            "38/38 [==============================] - 0s 328us/step - loss: 0.6692 - acc: 0.5789 - val_loss: 0.6368 - val_acc: 0.8000\n",
            "Epoch 18/200\n",
            "38/38 [==============================] - 0s 446us/step - loss: 0.6661 - acc: 0.6579 - val_loss: 0.6437 - val_acc: 0.8000\n",
            "Epoch 19/200\n",
            "38/38 [==============================] - 0s 359us/step - loss: 0.6653 - acc: 0.6579 - val_loss: 0.6518 - val_acc: 0.8000\n",
            "Epoch 20/200\n",
            "38/38 [==============================] - 0s 285us/step - loss: 0.6646 - acc: 0.6842 - val_loss: 0.6594 - val_acc: 0.8000\n",
            "Epoch 21/200\n",
            "38/38 [==============================] - 0s 422us/step - loss: 0.6635 - acc: 0.6842 - val_loss: 0.6649 - val_acc: 0.8000\n",
            "Epoch 22/200\n",
            "38/38 [==============================] - 0s 490us/step - loss: 0.6616 - acc: 0.6842 - val_loss: 0.6645 - val_acc: 0.8000\n",
            "Epoch 23/200\n",
            "38/38 [==============================] - 0s 358us/step - loss: 0.6604 - acc: 0.6842 - val_loss: 0.6649 - val_acc: 0.8000\n",
            "Epoch 24/200\n",
            "38/38 [==============================] - 0s 439us/step - loss: 0.6605 - acc: 0.7105 - val_loss: 0.6692 - val_acc: 0.8000\n",
            "Epoch 25/200\n",
            "38/38 [==============================] - 0s 395us/step - loss: 0.6595 - acc: 0.7105 - val_loss: 0.6656 - val_acc: 0.8000\n",
            "Epoch 26/200\n",
            "38/38 [==============================] - 0s 540us/step - loss: 0.6576 - acc: 0.7105 - val_loss: 0.6659 - val_acc: 0.8000\n",
            "Epoch 27/200\n",
            "38/38 [==============================] - 0s 401us/step - loss: 0.6569 - acc: 0.7105 - val_loss: 0.6682 - val_acc: 0.8000\n",
            "Epoch 28/200\n",
            "38/38 [==============================] - 0s 363us/step - loss: 0.6557 - acc: 0.7105 - val_loss: 0.6681 - val_acc: 0.8000\n",
            "Epoch 29/200\n",
            "38/38 [==============================] - 0s 282us/step - loss: 0.6547 - acc: 0.7105 - val_loss: 0.6684 - val_acc: 0.8000\n",
            "Epoch 30/200\n",
            "38/38 [==============================] - 0s 341us/step - loss: 0.6541 - acc: 0.7105 - val_loss: 0.6706 - val_acc: 0.8000\n",
            "Epoch 31/200\n",
            "38/38 [==============================] - 0s 364us/step - loss: 0.6535 - acc: 0.7105 - val_loss: 0.6732 - val_acc: 0.8000\n",
            "Epoch 32/200\n",
            "38/38 [==============================] - 0s 292us/step - loss: 0.6528 - acc: 0.7105 - val_loss: 0.6735 - val_acc: 0.8000\n",
            "Epoch 33/200\n",
            "38/38 [==============================] - 0s 329us/step - loss: 0.6520 - acc: 0.7105 - val_loss: 0.6728 - val_acc: 0.8000\n",
            "Epoch 34/200\n",
            "38/38 [==============================] - 0s 313us/step - loss: 0.6512 - acc: 0.7105 - val_loss: 0.6745 - val_acc: 0.8000\n",
            "Epoch 35/200\n",
            "38/38 [==============================] - 0s 313us/step - loss: 0.6505 - acc: 0.7105 - val_loss: 0.6754 - val_acc: 0.8000\n",
            "Epoch 36/200\n",
            "38/38 [==============================] - 0s 311us/step - loss: 0.6497 - acc: 0.7105 - val_loss: 0.6776 - val_acc: 0.8000\n",
            "Epoch 37/200\n",
            "38/38 [==============================] - 0s 371us/step - loss: 0.6493 - acc: 0.7105 - val_loss: 0.6815 - val_acc: 0.6000\n",
            "Epoch 38/200\n",
            "38/38 [==============================] - 0s 340us/step - loss: 0.6484 - acc: 0.7105 - val_loss: 0.6831 - val_acc: 0.6000\n",
            "Epoch 39/200\n",
            "38/38 [==============================] - 0s 372us/step - loss: 0.6478 - acc: 0.7105 - val_loss: 0.6834 - val_acc: 0.6000\n",
            "Epoch 40/200\n",
            "38/38 [==============================] - 0s 358us/step - loss: 0.6480 - acc: 0.7105 - val_loss: 0.6805 - val_acc: 0.7000\n",
            "Epoch 41/200\n",
            "38/38 [==============================] - 0s 285us/step - loss: 0.6468 - acc: 0.7105 - val_loss: 0.6847 - val_acc: 0.6000\n",
            "Epoch 42/200\n",
            "38/38 [==============================] - 0s 308us/step - loss: 0.6462 - acc: 0.7105 - val_loss: 0.6834 - val_acc: 0.6000\n",
            "Epoch 43/200\n",
            "38/38 [==============================] - 0s 284us/step - loss: 0.6453 - acc: 0.7105 - val_loss: 0.6871 - val_acc: 0.6000\n",
            "Epoch 44/200\n",
            "38/38 [==============================] - 0s 422us/step - loss: 0.6444 - acc: 0.7105 - val_loss: 0.6875 - val_acc: 0.6000\n",
            "Epoch 45/200\n",
            "38/38 [==============================] - 0s 290us/step - loss: 0.6440 - acc: 0.6842 - val_loss: 0.6894 - val_acc: 0.6000\n",
            "Epoch 46/200\n",
            "38/38 [==============================] - 0s 290us/step - loss: 0.6431 - acc: 0.6842 - val_loss: 0.6898 - val_acc: 0.6000\n",
            "Epoch 47/200\n",
            "38/38 [==============================] - 0s 253us/step - loss: 0.6427 - acc: 0.6842 - val_loss: 0.6881 - val_acc: 0.6000\n",
            "Epoch 48/200\n",
            "38/38 [==============================] - 0s 299us/step - loss: 0.6419 - acc: 0.6842 - val_loss: 0.6900 - val_acc: 0.6000\n",
            "Epoch 49/200\n",
            "38/38 [==============================] - 0s 285us/step - loss: 0.6418 - acc: 0.7105 - val_loss: 0.6877 - val_acc: 0.6000\n",
            "Epoch 50/200\n",
            "38/38 [==============================] - 0s 339us/step - loss: 0.6406 - acc: 0.6842 - val_loss: 0.6886 - val_acc: 0.6000\n",
            "Epoch 51/200\n",
            "38/38 [==============================] - 0s 500us/step - loss: 0.6399 - acc: 0.6842 - val_loss: 0.6883 - val_acc: 0.6000\n",
            "Epoch 52/200\n",
            "38/38 [==============================] - 0s 347us/step - loss: 0.6399 - acc: 0.7105 - val_loss: 0.6864 - val_acc: 0.6000\n",
            "Epoch 53/200\n",
            "38/38 [==============================] - 0s 350us/step - loss: 0.6393 - acc: 0.6842 - val_loss: 0.6913 - val_acc: 0.6000\n",
            "Epoch 54/200\n",
            "38/38 [==============================] - 0s 394us/step - loss: 0.6384 - acc: 0.6842 - val_loss: 0.6900 - val_acc: 0.6000\n",
            "Epoch 55/200\n",
            "38/38 [==============================] - 0s 333us/step - loss: 0.6382 - acc: 0.6842 - val_loss: 0.6947 - val_acc: 0.6000\n",
            "Epoch 56/200\n",
            "38/38 [==============================] - 0s 332us/step - loss: 0.6371 - acc: 0.6842 - val_loss: 0.6975 - val_acc: 0.6000\n",
            "Epoch 57/200\n",
            "38/38 [==============================] - 0s 578us/step - loss: 0.6365 - acc: 0.6842 - val_loss: 0.6945 - val_acc: 0.6000\n",
            "Epoch 58/200\n",
            "38/38 [==============================] - 0s 335us/step - loss: 0.6354 - acc: 0.6842 - val_loss: 0.6948 - val_acc: 0.6000\n",
            "Epoch 59/200\n",
            "38/38 [==============================] - 0s 360us/step - loss: 0.6349 - acc: 0.6842 - val_loss: 0.6933 - val_acc: 0.6000\n",
            "Epoch 60/200\n",
            "38/38 [==============================] - 0s 292us/step - loss: 0.6342 - acc: 0.6842 - val_loss: 0.6927 - val_acc: 0.6000\n",
            "Epoch 61/200\n",
            "38/38 [==============================] - 0s 322us/step - loss: 0.6337 - acc: 0.6842 - val_loss: 0.6955 - val_acc: 0.6000\n",
            "Epoch 62/200\n",
            "38/38 [==============================] - 0s 308us/step - loss: 0.6333 - acc: 0.6842 - val_loss: 0.6937 - val_acc: 0.6000\n",
            "Epoch 63/200\n",
            "38/38 [==============================] - 0s 409us/step - loss: 0.6333 - acc: 0.6842 - val_loss: 0.6988 - val_acc: 0.6000\n",
            "Epoch 64/200\n",
            "38/38 [==============================] - 0s 368us/step - loss: 0.6321 - acc: 0.6842 - val_loss: 0.6955 - val_acc: 0.6000\n",
            "Epoch 65/200\n",
            "38/38 [==============================] - 0s 267us/step - loss: 0.6310 - acc: 0.6842 - val_loss: 0.6954 - val_acc: 0.6000\n",
            "Epoch 66/200\n",
            "38/38 [==============================] - 0s 334us/step - loss: 0.6306 - acc: 0.6842 - val_loss: 0.6980 - val_acc: 0.5000\n",
            "Epoch 67/200\n",
            "38/38 [==============================] - 0s 344us/step - loss: 0.6297 - acc: 0.6842 - val_loss: 0.6983 - val_acc: 0.5000\n",
            "Epoch 68/200\n",
            "38/38 [==============================] - 0s 249us/step - loss: 0.6293 - acc: 0.6842 - val_loss: 0.6991 - val_acc: 0.5000\n",
            "Epoch 69/200\n",
            "38/38 [==============================] - 0s 252us/step - loss: 0.6290 - acc: 0.6842 - val_loss: 0.7012 - val_acc: 0.5000\n",
            "Epoch 70/200\n",
            "38/38 [==============================] - 0s 279us/step - loss: 0.6281 - acc: 0.6842 - val_loss: 0.6999 - val_acc: 0.5000\n",
            "Epoch 71/200\n",
            "38/38 [==============================] - 0s 375us/step - loss: 0.6276 - acc: 0.6842 - val_loss: 0.7011 - val_acc: 0.5000\n",
            "Epoch 72/200\n",
            "38/38 [==============================] - 0s 322us/step - loss: 0.6268 - acc: 0.6842 - val_loss: 0.7002 - val_acc: 0.5000\n",
            "Epoch 73/200\n",
            "38/38 [==============================] - 0s 376us/step - loss: 0.6264 - acc: 0.6842 - val_loss: 0.6982 - val_acc: 0.5000\n",
            "Epoch 74/200\n",
            "38/38 [==============================] - 0s 413us/step - loss: 0.6257 - acc: 0.6842 - val_loss: 0.6962 - val_acc: 0.5000\n",
            "Epoch 75/200\n",
            "38/38 [==============================] - 0s 490us/step - loss: 0.6249 - acc: 0.6842 - val_loss: 0.6970 - val_acc: 0.5000\n",
            "Epoch 76/200\n",
            "38/38 [==============================] - 0s 381us/step - loss: 0.6248 - acc: 0.6842 - val_loss: 0.6999 - val_acc: 0.5000\n",
            "Epoch 77/200\n",
            "38/38 [==============================] - 0s 382us/step - loss: 0.6240 - acc: 0.6842 - val_loss: 0.7007 - val_acc: 0.5000\n",
            "Epoch 78/200\n",
            "38/38 [==============================] - 0s 282us/step - loss: 0.6232 - acc: 0.6842 - val_loss: 0.6959 - val_acc: 0.5000\n",
            "Epoch 79/200\n",
            "38/38 [==============================] - 0s 365us/step - loss: 0.6227 - acc: 0.6842 - val_loss: 0.6931 - val_acc: 0.6000\n",
            "Epoch 80/200\n",
            "38/38 [==============================] - 0s 283us/step - loss: 0.6221 - acc: 0.6842 - val_loss: 0.6946 - val_acc: 0.6000\n",
            "Epoch 81/200\n",
            "38/38 [==============================] - 0s 341us/step - loss: 0.6214 - acc: 0.6842 - val_loss: 0.6942 - val_acc: 0.6000\n",
            "Epoch 82/200\n",
            "38/38 [==============================] - 0s 502us/step - loss: 0.6212 - acc: 0.6842 - val_loss: 0.6966 - val_acc: 0.6000\n",
            "Epoch 83/200\n",
            "38/38 [==============================] - 0s 360us/step - loss: 0.6205 - acc: 0.6842 - val_loss: 0.6966 - val_acc: 0.6000\n",
            "Epoch 84/200\n",
            "38/38 [==============================] - 0s 510us/step - loss: 0.6199 - acc: 0.6842 - val_loss: 0.6950 - val_acc: 0.6000\n",
            "Epoch 85/200\n",
            "38/38 [==============================] - 0s 387us/step - loss: 0.6193 - acc: 0.7105 - val_loss: 0.6945 - val_acc: 0.6000\n",
            "Epoch 86/200\n",
            "38/38 [==============================] - 0s 354us/step - loss: 0.6187 - acc: 0.6842 - val_loss: 0.6970 - val_acc: 0.6000\n",
            "Epoch 87/200\n",
            "38/38 [==============================] - 0s 467us/step - loss: 0.6187 - acc: 0.6842 - val_loss: 0.6950 - val_acc: 0.6000\n",
            "Epoch 88/200\n",
            "38/38 [==============================] - 0s 319us/step - loss: 0.6182 - acc: 0.7105 - val_loss: 0.6942 - val_acc: 0.6000\n",
            "Epoch 89/200\n",
            "38/38 [==============================] - 0s 444us/step - loss: 0.6167 - acc: 0.6842 - val_loss: 0.6991 - val_acc: 0.6000\n",
            "Epoch 90/200\n",
            "38/38 [==============================] - 0s 336us/step - loss: 0.6162 - acc: 0.6842 - val_loss: 0.7039 - val_acc: 0.5000\n",
            "Epoch 91/200\n",
            "38/38 [==============================] - 0s 277us/step - loss: 0.6157 - acc: 0.6842 - val_loss: 0.7058 - val_acc: 0.5000\n",
            "Epoch 92/200\n",
            "38/38 [==============================] - 0s 305us/step - loss: 0.6159 - acc: 0.6579 - val_loss: 0.7115 - val_acc: 0.5000\n",
            "Epoch 93/200\n",
            "38/38 [==============================] - 0s 287us/step - loss: 0.6155 - acc: 0.6579 - val_loss: 0.7090 - val_acc: 0.5000\n",
            "Epoch 94/200\n",
            "38/38 [==============================] - 0s 241us/step - loss: 0.6141 - acc: 0.6579 - val_loss: 0.7108 - val_acc: 0.5000\n",
            "Epoch 95/200\n",
            "38/38 [==============================] - 0s 384us/step - loss: 0.6153 - acc: 0.6579 - val_loss: 0.7063 - val_acc: 0.5000\n",
            "Epoch 96/200\n",
            "38/38 [==============================] - 0s 326us/step - loss: 0.6132 - acc: 0.6842 - val_loss: 0.7106 - val_acc: 0.5000\n",
            "Epoch 97/200\n",
            "38/38 [==============================] - 0s 304us/step - loss: 0.6126 - acc: 0.6842 - val_loss: 0.7099 - val_acc: 0.5000\n",
            "Epoch 98/200\n",
            "38/38 [==============================] - 0s 384us/step - loss: 0.6131 - acc: 0.6842 - val_loss: 0.7148 - val_acc: 0.5000\n",
            "Epoch 99/200\n",
            "38/38 [==============================] - 0s 383us/step - loss: 0.6120 - acc: 0.6842 - val_loss: 0.7088 - val_acc: 0.5000\n",
            "Epoch 100/200\n",
            "38/38 [==============================] - 0s 364us/step - loss: 0.6107 - acc: 0.6842 - val_loss: 0.7086 - val_acc: 0.5000\n",
            "Epoch 101/200\n",
            "38/38 [==============================] - 0s 311us/step - loss: 0.6100 - acc: 0.6842 - val_loss: 0.7068 - val_acc: 0.5000\n",
            "Epoch 102/200\n",
            "38/38 [==============================] - 0s 407us/step - loss: 0.6104 - acc: 0.6579 - val_loss: 0.7067 - val_acc: 0.6000\n",
            "Epoch 103/200\n",
            "38/38 [==============================] - 0s 317us/step - loss: 0.6094 - acc: 0.6842 - val_loss: 0.7076 - val_acc: 0.5000\n",
            "Epoch 104/200\n",
            "38/38 [==============================] - 0s 287us/step - loss: 0.6087 - acc: 0.6842 - val_loss: 0.7038 - val_acc: 0.6000\n",
            "Epoch 105/200\n",
            "38/38 [==============================] - 0s 277us/step - loss: 0.6080 - acc: 0.7105 - val_loss: 0.7035 - val_acc: 0.6000\n",
            "Epoch 106/200\n",
            "38/38 [==============================] - 0s 364us/step - loss: 0.6076 - acc: 0.6842 - val_loss: 0.7038 - val_acc: 0.6000\n",
            "Epoch 107/200\n",
            "38/38 [==============================] - 0s 271us/step - loss: 0.6097 - acc: 0.7105 - val_loss: 0.6978 - val_acc: 0.6000\n",
            "Epoch 108/200\n",
            "38/38 [==============================] - 0s 247us/step - loss: 0.6075 - acc: 0.7368 - val_loss: 0.7056 - val_acc: 0.6000\n",
            "Epoch 109/200\n",
            "38/38 [==============================] - 0s 288us/step - loss: 0.6065 - acc: 0.7105 - val_loss: 0.7099 - val_acc: 0.6000\n",
            "Epoch 110/200\n",
            "38/38 [==============================] - 0s 448us/step - loss: 0.6053 - acc: 0.6842 - val_loss: 0.7106 - val_acc: 0.6000\n",
            "Epoch 111/200\n",
            "38/38 [==============================] - 0s 327us/step - loss: 0.6049 - acc: 0.6842 - val_loss: 0.7108 - val_acc: 0.6000\n",
            "Epoch 112/200\n",
            "38/38 [==============================] - 0s 380us/step - loss: 0.6042 - acc: 0.6842 - val_loss: 0.7109 - val_acc: 0.6000\n",
            "Epoch 113/200\n",
            "38/38 [==============================] - 0s 319us/step - loss: 0.6041 - acc: 0.7105 - val_loss: 0.7059 - val_acc: 0.6000\n",
            "Epoch 114/200\n",
            "38/38 [==============================] - 0s 561us/step - loss: 0.6033 - acc: 0.7105 - val_loss: 0.7061 - val_acc: 0.6000\n",
            "Epoch 115/200\n",
            "38/38 [==============================] - 0s 329us/step - loss: 0.6031 - acc: 0.7105 - val_loss: 0.7091 - val_acc: 0.6000\n",
            "Epoch 116/200\n",
            "38/38 [==============================] - 0s 254us/step - loss: 0.6020 - acc: 0.7105 - val_loss: 0.7085 - val_acc: 0.6000\n",
            "Epoch 117/200\n",
            "38/38 [==============================] - 0s 271us/step - loss: 0.6015 - acc: 0.7105 - val_loss: 0.7093 - val_acc: 0.6000\n",
            "Epoch 118/200\n",
            "38/38 [==============================] - 0s 317us/step - loss: 0.6015 - acc: 0.7105 - val_loss: 0.7084 - val_acc: 0.6000\n",
            "Epoch 119/200\n",
            "38/38 [==============================] - 0s 355us/step - loss: 0.6007 - acc: 0.7105 - val_loss: 0.7099 - val_acc: 0.6000\n",
            "Epoch 120/200\n",
            "38/38 [==============================] - 0s 435us/step - loss: 0.6003 - acc: 0.7105 - val_loss: 0.7169 - val_acc: 0.5000\n",
            "Epoch 121/200\n",
            "38/38 [==============================] - 0s 381us/step - loss: 0.5992 - acc: 0.7105 - val_loss: 0.7180 - val_acc: 0.5000\n",
            "Epoch 122/200\n",
            "38/38 [==============================] - 0s 308us/step - loss: 0.5994 - acc: 0.7105 - val_loss: 0.7241 - val_acc: 0.4000\n",
            "Epoch 123/200\n",
            "38/38 [==============================] - 0s 343us/step - loss: 0.5984 - acc: 0.6842 - val_loss: 0.7211 - val_acc: 0.4000\n",
            "Epoch 124/200\n",
            "38/38 [==============================] - 0s 303us/step - loss: 0.5985 - acc: 0.6842 - val_loss: 0.7224 - val_acc: 0.4000\n",
            "Epoch 125/200\n",
            "38/38 [==============================] - 0s 336us/step - loss: 0.5969 - acc: 0.6842 - val_loss: 0.7223 - val_acc: 0.4000\n",
            "Epoch 126/200\n",
            "38/38 [==============================] - 0s 356us/step - loss: 0.5965 - acc: 0.7105 - val_loss: 0.7230 - val_acc: 0.4000\n",
            "Epoch 127/200\n",
            "38/38 [==============================] - 0s 288us/step - loss: 0.5959 - acc: 0.7105 - val_loss: 0.7224 - val_acc: 0.5000\n",
            "Epoch 128/200\n",
            "38/38 [==============================] - 0s 427us/step - loss: 0.5955 - acc: 0.7105 - val_loss: 0.7265 - val_acc: 0.4000\n",
            "Epoch 129/200\n",
            "38/38 [==============================] - 0s 315us/step - loss: 0.5958 - acc: 0.7105 - val_loss: 0.7295 - val_acc: 0.4000\n",
            "Epoch 130/200\n",
            "38/38 [==============================] - 0s 277us/step - loss: 0.5942 - acc: 0.7105 - val_loss: 0.7244 - val_acc: 0.5000\n",
            "Epoch 131/200\n",
            "38/38 [==============================] - 0s 289us/step - loss: 0.5934 - acc: 0.7368 - val_loss: 0.7202 - val_acc: 0.5000\n",
            "Epoch 132/200\n",
            "38/38 [==============================] - 0s 293us/step - loss: 0.5931 - acc: 0.7368 - val_loss: 0.7219 - val_acc: 0.5000\n",
            "Epoch 133/200\n",
            "38/38 [==============================] - 0s 464us/step - loss: 0.5922 - acc: 0.7368 - val_loss: 0.7198 - val_acc: 0.5000\n",
            "Epoch 134/200\n",
            "38/38 [==============================] - 0s 358us/step - loss: 0.5913 - acc: 0.7368 - val_loss: 0.7207 - val_acc: 0.5000\n",
            "Epoch 135/200\n",
            "38/38 [==============================] - 0s 330us/step - loss: 0.5911 - acc: 0.7368 - val_loss: 0.7200 - val_acc: 0.5000\n",
            "Epoch 136/200\n",
            "38/38 [==============================] - 0s 299us/step - loss: 0.5897 - acc: 0.7368 - val_loss: 0.7199 - val_acc: 0.5000\n",
            "Epoch 137/200\n",
            "38/38 [==============================] - 0s 306us/step - loss: 0.5891 - acc: 0.7368 - val_loss: 0.7258 - val_acc: 0.5000\n",
            "Epoch 138/200\n",
            "38/38 [==============================] - 0s 324us/step - loss: 0.5881 - acc: 0.6842 - val_loss: 0.7282 - val_acc: 0.5000\n",
            "Epoch 139/200\n",
            "38/38 [==============================] - 0s 277us/step - loss: 0.5873 - acc: 0.6842 - val_loss: 0.7287 - val_acc: 0.5000\n",
            "Epoch 140/200\n",
            "38/38 [==============================] - 0s 420us/step - loss: 0.5865 - acc: 0.7105 - val_loss: 0.7264 - val_acc: 0.5000\n",
            "Epoch 141/200\n",
            "38/38 [==============================] - 0s 394us/step - loss: 0.5866 - acc: 0.7105 - val_loss: 0.7326 - val_acc: 0.5000\n",
            "Epoch 142/200\n",
            "38/38 [==============================] - 0s 426us/step - loss: 0.5846 - acc: 0.6842 - val_loss: 0.7320 - val_acc: 0.5000\n",
            "Epoch 143/200\n",
            "38/38 [==============================] - 0s 288us/step - loss: 0.5851 - acc: 0.7105 - val_loss: 0.7237 - val_acc: 0.5000\n",
            "Epoch 144/200\n",
            "38/38 [==============================] - 0s 284us/step - loss: 0.5828 - acc: 0.7368 - val_loss: 0.7222 - val_acc: 0.5000\n",
            "Epoch 145/200\n",
            "38/38 [==============================] - 0s 370us/step - loss: 0.5822 - acc: 0.7368 - val_loss: 0.7218 - val_acc: 0.5000\n",
            "Epoch 146/200\n",
            "38/38 [==============================] - 0s 395us/step - loss: 0.5819 - acc: 0.7368 - val_loss: 0.7247 - val_acc: 0.5000\n",
            "Epoch 147/200\n",
            "38/38 [==============================] - 0s 271us/step - loss: 0.5808 - acc: 0.7368 - val_loss: 0.7224 - val_acc: 0.5000\n",
            "Epoch 148/200\n",
            "38/38 [==============================] - 0s 453us/step - loss: 0.5802 - acc: 0.7368 - val_loss: 0.7202 - val_acc: 0.5000\n",
            "Epoch 149/200\n",
            "38/38 [==============================] - 0s 317us/step - loss: 0.5795 - acc: 0.7368 - val_loss: 0.7188 - val_acc: 0.5000\n",
            "Epoch 150/200\n",
            "38/38 [==============================] - 0s 295us/step - loss: 0.5793 - acc: 0.7368 - val_loss: 0.7191 - val_acc: 0.5000\n",
            "Epoch 151/200\n",
            "38/38 [==============================] - 0s 371us/step - loss: 0.5782 - acc: 0.7368 - val_loss: 0.7219 - val_acc: 0.5000\n",
            "Epoch 152/200\n",
            "38/38 [==============================] - 0s 285us/step - loss: 0.5781 - acc: 0.7368 - val_loss: 0.7273 - val_acc: 0.5000\n",
            "Epoch 153/200\n",
            "38/38 [==============================] - 0s 399us/step - loss: 0.5770 - acc: 0.7368 - val_loss: 0.7282 - val_acc: 0.5000\n",
            "Epoch 154/200\n",
            "38/38 [==============================] - 0s 348us/step - loss: 0.5772 - acc: 0.7368 - val_loss: 0.7255 - val_acc: 0.5000\n",
            "Epoch 155/200\n",
            "38/38 [==============================] - 0s 252us/step - loss: 0.5763 - acc: 0.7368 - val_loss: 0.7265 - val_acc: 0.5000\n",
            "Epoch 156/200\n",
            "38/38 [==============================] - 0s 392us/step - loss: 0.5770 - acc: 0.7368 - val_loss: 0.7357 - val_acc: 0.5000\n",
            "Epoch 157/200\n",
            "38/38 [==============================] - 0s 304us/step - loss: 0.5749 - acc: 0.7105 - val_loss: 0.7385 - val_acc: 0.5000\n",
            "Epoch 158/200\n",
            "38/38 [==============================] - 0s 462us/step - loss: 0.5749 - acc: 0.7368 - val_loss: 0.7321 - val_acc: 0.5000\n",
            "Epoch 159/200\n",
            "38/38 [==============================] - 0s 319us/step - loss: 0.5741 - acc: 0.7368 - val_loss: 0.7293 - val_acc: 0.5000\n",
            "Epoch 160/200\n",
            "38/38 [==============================] - 0s 426us/step - loss: 0.5731 - acc: 0.7368 - val_loss: 0.7307 - val_acc: 0.5000\n",
            "Epoch 161/200\n",
            "38/38 [==============================] - 0s 335us/step - loss: 0.5719 - acc: 0.7368 - val_loss: 0.7378 - val_acc: 0.5000\n",
            "Epoch 162/200\n",
            "38/38 [==============================] - 0s 320us/step - loss: 0.5715 - acc: 0.7368 - val_loss: 0.7415 - val_acc: 0.5000\n",
            "Epoch 163/200\n",
            "38/38 [==============================] - 0s 332us/step - loss: 0.5711 - acc: 0.7105 - val_loss: 0.7464 - val_acc: 0.5000\n",
            "Epoch 164/200\n",
            "38/38 [==============================] - 0s 333us/step - loss: 0.5706 - acc: 0.7105 - val_loss: 0.7471 - val_acc: 0.5000\n",
            "Epoch 165/200\n",
            "38/38 [==============================] - 0s 434us/step - loss: 0.5698 - acc: 0.7105 - val_loss: 0.7479 - val_acc: 0.5000\n",
            "Epoch 166/200\n",
            "38/38 [==============================] - 0s 334us/step - loss: 0.5699 - acc: 0.7105 - val_loss: 0.7469 - val_acc: 0.5000\n",
            "Epoch 167/200\n",
            "38/38 [==============================] - 0s 377us/step - loss: 0.5691 - acc: 0.7105 - val_loss: 0.7504 - val_acc: 0.5000\n",
            "Epoch 168/200\n",
            "38/38 [==============================] - 0s 327us/step - loss: 0.5686 - acc: 0.7105 - val_loss: 0.7465 - val_acc: 0.5000\n",
            "Epoch 169/200\n",
            "38/38 [==============================] - 0s 283us/step - loss: 0.5676 - acc: 0.7105 - val_loss: 0.7500 - val_acc: 0.5000\n",
            "Epoch 170/200\n",
            "38/38 [==============================] - 0s 288us/step - loss: 0.5671 - acc: 0.7105 - val_loss: 0.7517 - val_acc: 0.5000\n",
            "Epoch 171/200\n",
            "38/38 [==============================] - 0s 345us/step - loss: 0.5662 - acc: 0.7105 - val_loss: 0.7476 - val_acc: 0.5000\n",
            "Epoch 172/200\n",
            "38/38 [==============================] - 0s 364us/step - loss: 0.5656 - acc: 0.7368 - val_loss: 0.7436 - val_acc: 0.5000\n",
            "Epoch 173/200\n",
            "38/38 [==============================] - 0s 349us/step - loss: 0.5652 - acc: 0.7368 - val_loss: 0.7425 - val_acc: 0.5000\n",
            "Epoch 174/200\n",
            "38/38 [==============================] - 0s 336us/step - loss: 0.5657 - acc: 0.7368 - val_loss: 0.7366 - val_acc: 0.5000\n",
            "Epoch 175/200\n",
            "38/38 [==============================] - 0s 288us/step - loss: 0.5640 - acc: 0.7368 - val_loss: 0.7402 - val_acc: 0.5000\n",
            "Epoch 176/200\n",
            "38/38 [==============================] - 0s 270us/step - loss: 0.5632 - acc: 0.7368 - val_loss: 0.7460 - val_acc: 0.5000\n",
            "Epoch 177/200\n",
            "38/38 [==============================] - 0s 235us/step - loss: 0.5629 - acc: 0.7368 - val_loss: 0.7477 - val_acc: 0.5000\n",
            "Epoch 178/200\n",
            "38/38 [==============================] - 0s 335us/step - loss: 0.5629 - acc: 0.7368 - val_loss: 0.7531 - val_acc: 0.5000\n",
            "Epoch 179/200\n",
            "38/38 [==============================] - 0s 354us/step - loss: 0.5617 - acc: 0.7105 - val_loss: 0.7524 - val_acc: 0.5000\n",
            "Epoch 180/200\n",
            "38/38 [==============================] - 0s 423us/step - loss: 0.5617 - acc: 0.7368 - val_loss: 0.7484 - val_acc: 0.5000\n",
            "Epoch 181/200\n",
            "38/38 [==============================] - 0s 351us/step - loss: 0.5605 - acc: 0.7368 - val_loss: 0.7524 - val_acc: 0.5000\n",
            "Epoch 182/200\n",
            "38/38 [==============================] - 0s 360us/step - loss: 0.5599 - acc: 0.7368 - val_loss: 0.7533 - val_acc: 0.6000\n",
            "Epoch 183/200\n",
            "38/38 [==============================] - 0s 335us/step - loss: 0.5596 - acc: 0.7105 - val_loss: 0.7567 - val_acc: 0.6000\n",
            "Epoch 184/200\n",
            "38/38 [==============================] - 0s 403us/step - loss: 0.5590 - acc: 0.7105 - val_loss: 0.7572 - val_acc: 0.6000\n",
            "Epoch 185/200\n",
            "38/38 [==============================] - 0s 454us/step - loss: 0.5586 - acc: 0.7105 - val_loss: 0.7567 - val_acc: 0.6000\n",
            "Epoch 186/200\n",
            "38/38 [==============================] - 0s 409us/step - loss: 0.5581 - acc: 0.7105 - val_loss: 0.7583 - val_acc: 0.6000\n",
            "Epoch 187/200\n",
            "38/38 [==============================] - 0s 413us/step - loss: 0.5576 - acc: 0.7105 - val_loss: 0.7615 - val_acc: 0.6000\n",
            "Epoch 188/200\n",
            "38/38 [==============================] - 0s 408us/step - loss: 0.5572 - acc: 0.7368 - val_loss: 0.7566 - val_acc: 0.6000\n",
            "Epoch 189/200\n",
            "38/38 [==============================] - 0s 351us/step - loss: 0.5561 - acc: 0.7368 - val_loss: 0.7562 - val_acc: 0.6000\n",
            "Epoch 190/200\n",
            "38/38 [==============================] - 0s 498us/step - loss: 0.5562 - acc: 0.7368 - val_loss: 0.7550 - val_acc: 0.6000\n",
            "Epoch 191/200\n",
            "38/38 [==============================] - 0s 353us/step - loss: 0.5556 - acc: 0.7368 - val_loss: 0.7598 - val_acc: 0.6000\n",
            "Epoch 192/200\n",
            "38/38 [==============================] - 0s 288us/step - loss: 0.5546 - acc: 0.7368 - val_loss: 0.7571 - val_acc: 0.6000\n",
            "Epoch 193/200\n",
            "38/38 [==============================] - 0s 301us/step - loss: 0.5556 - acc: 0.7368 - val_loss: 0.7530 - val_acc: 0.6000\n",
            "Epoch 194/200\n",
            "38/38 [==============================] - 0s 285us/step - loss: 0.5540 - acc: 0.7368 - val_loss: 0.7525 - val_acc: 0.5000\n",
            "Epoch 195/200\n",
            "38/38 [==============================] - 0s 274us/step - loss: 0.5532 - acc: 0.7368 - val_loss: 0.7550 - val_acc: 0.6000\n",
            "Epoch 196/200\n",
            "38/38 [==============================] - 0s 252us/step - loss: 0.5527 - acc: 0.7368 - val_loss: 0.7624 - val_acc: 0.6000\n",
            "Epoch 197/200\n",
            "38/38 [==============================] - 0s 297us/step - loss: 0.5521 - acc: 0.7368 - val_loss: 0.7639 - val_acc: 0.6000\n",
            "Epoch 198/200\n",
            "38/38 [==============================] - 0s 389us/step - loss: 0.5515 - acc: 0.7368 - val_loss: 0.7662 - val_acc: 0.6000\n",
            "Epoch 199/200\n",
            "38/38 [==============================] - 0s 342us/step - loss: 0.5513 - acc: 0.7105 - val_loss: 0.7686 - val_acc: 0.6000\n",
            "Epoch 200/200\n",
            "38/38 [==============================] - 0s 342us/step - loss: 0.5509 - acc: 0.7368 - val_loss: 0.7657 - val_acc: 0.6000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f175197cef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq1swH0sPZvo",
        "colab_type": "code",
        "outputId": "413b0326-43a9-4cdd-9a64-3ae5d9fdd3a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import numpy as np\n",
        "#load dataset\n",
        "dataset = loadtxt ('T-median.csv', delimiter = ',')\n",
        "#split dataset into input and output variables\n",
        "x = dataset [:, 0:13]\n",
        "y = dataset [:, 13]\n",
        "# define 10-fold cross validation test harness\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "cvscores = []\n",
        "for train, test in kfold.split(x, y):\n",
        "  # create model\n",
        "  model = Sequential ()\n",
        "  model.add(Dense(12, input_dim=13, activation='relu'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  # Compile model\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  # Fit the model\n",
        "  model.fit(x[train], y[train], epochs=200, batch_size=10, verbose=0)\n",
        "  # evaluate the model\n",
        "  scores = model.evaluate(x[test], y[test], verbose=0)\n",
        "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  cvscores.append(scores[1] * 100)\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc: 20.00%\n",
            "acc: 40.00%\n",
            "acc: 60.00%\n",
            "acc: 60.00%\n",
            "acc: 60.00%\n",
            "acc: 80.00%\n",
            "acc: 80.00%\n",
            "acc: 60.00%\n",
            "acc: 75.00%\n",
            "acc: 50.00%\n",
            "58.50% (+/- 17.61%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}